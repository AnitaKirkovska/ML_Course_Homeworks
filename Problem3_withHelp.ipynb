{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Problem3-withHelp.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnitaKirkovska/MachineLearning_HW1/blob/master/Problem3_withHelp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "b9NwlwTLk86o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0188e8a4-e81a-4f2a-f952-007cad965e5a"
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "from keras import backend as K\n",
        "import keras\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "fO9VSWlD4Rmw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "I had challenges doing the third problem myself, so with a colleague of mine he helped me do it his way. Here is the code that I've developed with his help. I don't know if it can count towards the grade, but I really hope so. The other solution is only my work. "
      ]
    },
    {
      "metadata": {
        "id": "8DtNDn-ClCpr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "(x_train_org, y_train_org),(x_test_org, y_test_org) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1af4bYdRlElV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train = x_train_org.reshape((60000, 28 * 28))\n",
        "x_train = x_train_org.astype('float32') / 255\n",
        "\n",
        "x_test = x_test_org.reshape((10000, 28 * 28))\n",
        "x_test = x_test_org.astype('float32') / 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-saoIB044qRW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "10 Classes with categorical labels"
      ]
    },
    {
      "metadata": {
        "id": "cCRcAmj8ltuN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train = x_train.reshape(x_train.shape[0], -1)\n",
        "x_test = x_test.reshape(x_test.shape[0], -1)\n",
        "y_train = to_categorical(y_train_org, num_classes=10) \n",
        "y_test = to_categorical(y_test_org, num_classes=10)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gurWtZIllvkL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def update_links(w,b,X):\n",
        "  return np.dot(X,w.T) + b\n",
        "def softmax(links):\n",
        "  exp = np.exp(links)\n",
        "  sum_exp = np.sum(np.exp(links), axis=1, keepdims=True)\n",
        "  softmax = exp / sum_exp\n",
        "  return softmax\n",
        "def cross_entropy(X, Y, links):\n",
        "  m = X.shape[0]\n",
        "  loss = - (1 / m) * np.sum(Y * np.log(links))\n",
        "  return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6mJrLvjqmHNH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Transform vector y of labels to one-hot encoded matrix"
      ]
    },
    {
      "metadata": {
        "id": "mtfzZXaTmGcn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def one_hot(X, Y, num_class=10):\n",
        "  m = X.shape[0]\n",
        "  one_hot = np.zeros((m, num_class))\n",
        "  one_hot[np.arange(m), Y.T] = 1\n",
        "  return one_hot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KZBpEL4TmPRW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Weight and bias"
      ]
    },
    {
      "metadata": {
        "id": "TvY3FmnSmML8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def params_zeros(num_class, num_features):\n",
        "  w = np.random.rand(num_class, num_features)\n",
        "  b = np.zeros((1, num_class))\n",
        "  return w,b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mMUwKf1wnDin",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Prediction"
      ]
    },
    {
      "metadata": {
        "id": "lj2Fijc-mOIw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def predict(w,b,X):\n",
        "  links = update_links(w,b,X)\n",
        "  probs = softmax(links)\n",
        "  preds = np.argmax(probs,axis=1)\n",
        "\n",
        "  return preds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3nO8ekH9nFnT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Training"
      ]
    },
    {
      "metadata": {
        "id": "4wlUWYA8nFZS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(X_train, Y_train, batch_size=10, lr=0.01,num_class = 10):\n",
        "  train_samples,train_features = X_train.shape\n",
        "  w, b = params_zeros(num_class,train_features)\n",
        "  #print (w,b)\n",
        "  #print (train_samples, train_features)\n",
        "  #print(w.shape)\n",
        "  all_losses = []\n",
        "  #stochastic gradient regression\n",
        "  for item in range(batch_size):\n",
        "    cost = 0.0\n",
        "    for i in range(train_samples):\n",
        "      \n",
        "      rand_ind = np.random.randint(0,train_samples)\n",
        "      xi = X_train[rand_ind,:].reshape(1,train_features)\n",
        "      yi = Y_train[rand_ind].reshape(1,1)\n",
        "      \n",
        "      y_one_hot = one_hot(xi,yi)\n",
        "      scores = update_links(w,b,xi)\n",
        "      probs = softmax(scores)\n",
        "      loss = cross_entropy(xi,y_one_hot, probs)\n",
        "      \n",
        "      #print(probs.shape)\n",
        "      dw = (1. / train_samples) * np.dot((probs - y_one_hot).T,xi)\n",
        "      db = (1. / train_samples) * np.sum(probs - y_one_hot, axis=0)\n",
        "      \n",
        "      w = w - lr * dw\n",
        "      b = b - lr * db\n",
        "      \n",
        "    all_losses.append(loss)\n",
        "    \n",
        "    print(f'Iteration number: {item}, loss: {np.round(loss, 4)}')\n",
        "    \n",
        "  return w, b, all_losses"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Gb85TWLNmwb3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def model(X_train, Y_train, X_test, Y_test, batch_size, lr,num_class):\n",
        "  w, b, loss = train(X_train, Y_train, batch_size, lr, num_class)\n",
        "  \n",
        "  #predict test/train set examples \n",
        "  Y_pred_test = predict(w, b, X_test)\n",
        "  Y_pred_train = predict(w, b, X_train)\n",
        " \n",
        "  Y_true_test = np.argmax(Y_test, axis=0)\n",
        "  Y_true_train = np.argmax(Y_train,axis=0)\n",
        "                         \n",
        "\n",
        "  print(\"\")\n",
        "  print(\"train accuracy: {} %\".format(100*sum(Y_pred_train==Y_true_train)/(float(len(Y_train)))))\n",
        "  print(\"test accuracy: {} %\".format(100*sum(Y_pred_test==Y_true_test)/(float(len(Y_test)))))\n",
        " \n",
        "  d = {\"costs\": loss, \"Y_pred_test\": Y_pred_test, \n",
        "        \"Y_pred_train\" : Y_pred_train, \n",
        "        \"w\" : w, \n",
        "        \"b\" : b,\n",
        "        \"learning_rate\" : lr,\n",
        "        \"batch_size\": batch_size}\n",
        "    \n",
        "  return d"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "11FjI6wHtxfa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "002e65e5-d9a0-42e2-c17c-3db51a700bbc"
      },
      "cell_type": "code",
      "source": [
        "y_train_origin"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "metadata": {
        "id": "nZHR-AJInNjf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "4d5d12ec-b338-4cc8-b164-4adc7a65157e"
      },
      "cell_type": "code",
      "source": [
        "d = model(x_train, y_train_origin, x_test, y_test_origin, batch_size=20, lr=0.01,num_class=10)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration number: 0, loss: 8.3799\n",
            "Iteration number: 1, loss: 7.8428\n",
            "Iteration number: 2, loss: 4.3301\n",
            "Iteration number: 3, loss: 3.2686\n",
            "Iteration number: 4, loss: 0.0634\n",
            "Iteration number: 5, loss: 0.9258\n",
            "Iteration number: 6, loss: 2.9522\n",
            "Iteration number: 7, loss: 4.924\n",
            "Iteration number: 8, loss: 0.1159\n",
            "Iteration number: 9, loss: 3.7475\n",
            "Iteration number: 10, loss: 7.2633\n",
            "Iteration number: 11, loss: 4.9648\n",
            "Iteration number: 12, loss: 6.3069\n",
            "Iteration number: 13, loss: 5.7258\n",
            "Iteration number: 14, loss: 2.4418\n",
            "Iteration number: 15, loss: 4.8221\n",
            "Iteration number: 16, loss: 3.7392\n",
            "Iteration number: 17, loss: 3.1925\n",
            "Iteration number: 18, loss: 6.1743\n",
            "Iteration number: 19, loss: 3.7089\n",
            "\n",
            "train accuracy: 6.266666666666667 %\n",
            "test accuracy: 17.34 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aUr0xPpynP96",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}